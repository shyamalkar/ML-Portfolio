{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Set Up the SQLite Database\n",
        "Create a database to store the IMDB dataset (text reviews and sentiment labels).\n",
        "python\n",
        "\n"
      ],
      "metadata": {
        "id": "vKQYKu322RmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb4\n",
        "import numpy as np\n",
        "\n",
        "# Create/connect to SQLite database\n",
        "conn = sqlite3.connect('imdb_reviews.db')\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Create table for IMDB reviews\n",
        "cursor.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS reviews (\n",
        "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "        review_text TEXT NOT NULL,\n",
        "        sentiment INTEGER NOT NULL\n",
        "    )\n",
        "''')\n",
        "\n",
        "# Load IMDB dataset from TensorFlow\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
        "\n",
        "# Decode word indices back to text\n",
        "word_index = imdb.get_word_index()\n",
        "reverse_word_index = {value: key for key, value in word_index.items()}\n",
        "\n",
        "def decode_review(encoded_review):\n",
        "    return ' '.join([reverse_word_index.get(i - 3, '?') for i in encoded_review])\n",
        "\n",
        "# Insert training data into SQLite\n",
        "for review, label in zip(x_train, y_train):\n",
        "    text = decode_review(review)\n",
        "    cursor.execute('INSERT INTO reviews (review_text, sentiment) VALUES (?, ?)', (text, int(label)))\n",
        "conn.commit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgbCG5bjXLFj",
        "outputId": "dd49de1e-1260-4f84-e033-790c2dd14529"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "\u001b[1m1641221/1641221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Retrieve Data with SQL\n",
        "\n"
      ],
      "metadata": {
        "id": "3QpwrIgm2a_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch data from SQLite\n",
        "query = 'SELECT review_text, sentiment FROM reviews LIMIT 25000'  # Limit for demo\n",
        "df = pd.read_sql_query(query, conn)\n",
        "\n",
        "# Split into features and labels\n",
        "reviews = df['review_text'].values\n",
        "labels = df['sentiment'].values"
      ],
      "metadata": {
        "id": "uvN3hm9DXLH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocess the Text Data\n",
        "\n",
        "Convert text reviews into numerical format for TensorFlow."
      ],
      "metadata": {
        "id": "YK-3mpFD2dc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Tokenize and pad sequences\n",
        "max_words = 10000\n",
        "max_len = 200\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(reviews)\n",
        "sequences = tokenizer.texts_to_sequences(reviews)\n",
        "x_data = pad_sequences(sequences, maxlen=max_len)\n",
        "\n",
        "# Convert labels to categorical\n",
        "y_data = tf.keras.utils.to_categorical(labels, 2)"
      ],
      "metadata": {
        "id": "KVO4wXMDXLJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Split Data and Build the Model\n",
        "\n",
        "Use a simple LSTM model for text classification.\n",
        "\n"
      ],
      "metadata": {
        "id": "M8JNjTTk94i6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models, layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split into training and validation sets\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the model\n",
        "model = models.Sequential([\n",
        "    layers.Embedding(max_words, 128, input_length=max_len),\n",
        "    layers.LSTM(64, return_sequences=False),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Display model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "id": "rmTLPoD0XLL-",
        "outputId": "d7c26069-848b-4bda-d358-b5866a41c0cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train the Model\n",
        "\n",
        "Train the model on the processed data.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZPAsGMEA9-7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, epochs=5, batch_size=64,\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VupBg5bVXLOE",
        "outputId": "07d5346f-5b92-4bd4-9b4b-0d953640ef43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 287ms/step - accuracy: 0.6947 - loss: 0.5422 - val_accuracy: 0.8672 - val_loss: 0.3084\n",
            "Epoch 2/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 288ms/step - accuracy: 0.9074 - loss: 0.2397 - val_accuracy: 0.8532 - val_loss: 0.3297\n",
            "Epoch 3/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 281ms/step - accuracy: 0.9480 - loss: 0.1489 - val_accuracy: 0.8630 - val_loss: 0.3364\n",
            "Epoch 4/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 265ms/step - accuracy: 0.9647 - loss: 0.1009 - val_accuracy: 0.8594 - val_loss: 0.4267\n",
            "Epoch 5/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 282ms/step - accuracy: 0.9764 - loss: 0.0681 - val_accuracy: 0.8532 - val_loss: 0.5102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Save Predictions to SQLite\n",
        "\n",
        "Make predictions on a subset of data and store them back in the database.\n",
        "\n"
      ],
      "metadata": {
        "id": "yURxYZRD-Lxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create table for predictions\n",
        "cursor.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS predictions (\n",
        "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "        review text TEXT NOT NULL,\n",
        "        sentiment INTEGER,\n",
        "        predicted sentiment INTEGER,\n",
        "        confidence REAL\n",
        "    )\n",
        "''')\n",
        "\n",
        "# Predict on validation set\n",
        "predictions = model.predict(x_val[:100])  # Limit for demo\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "confidences = np.max(predictions, axis=1)\n",
        "\n",
        "# Insert predictions into SQLite\n",
        "for review, true_label, pred_label, confidence in zip(x_val[:100], np.argmax(y_val[:100], axis=1), predicted_labels, confidences):\n",
        "    review_text = ' '.join([tokenizer.index_word.get(i, '?') for i in review if i != 0])\n",
        "    cursor.execute('INSERT INTO predictions (review_text, sentiment, predicted_sentiment, confidence) VALUES (?, ?, ?, ?)',\n",
        "                  (review_text, int(true_label), int(pred_label), float(confidence)))\n",
        "conn.commit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wgr_4IF-XLP4",
        "outputId": "b6587414-aad1-4ac8-b154-751e12a3fbe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluate and Visualize\n",
        "\n",
        "Query the predictions and evaluate the model.\n",
        "\n"
      ],
      "metadata": {
        "id": "I0gnILOs-T8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Query predictions\n",
        "df_preds = pd.read_sql_query('SELECT * FROM predictions', conn)\n",
        "print(df_preds.head())\n",
        "\n",
        "# Plot training history\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Close database connection\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "w_t8enHwXLR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Database Interaction\n",
        "\n",
        "To explore the database:\n",
        "\n"
      ],
      "metadata": {
        "id": "XG306KpR-a2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conn = sqlite3.connect('imdb_reviews.db')\n",
        "df = pd.read_sql_query('SELECT * FROM reviews LIMIT 5', conn)\n",
        "print(df)\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "KhKZ87msXLUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7bTdJ0LeXLWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GbhQ_BjNXLYO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}